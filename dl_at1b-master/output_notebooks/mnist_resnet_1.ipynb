{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_mnist_1 import *\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_mnist_1 import *\n",
    "\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import ResNet and configure it \n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Activation, Flatten, MaxPool2D, BatchNormalization, GlobalAveragePooling2D, Dropout\n",
    "from keras.optimizers import Adam, Adadelta\n",
    "from keras.applications import ResNet50\n",
    "from keras.applications import resnet50 as resnet50\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model \n",
    "from keras.utils import to_categorical\n",
    "from keras.regularizers import l2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded data set from mnist_1 method\n"
     ]
    }
   ],
   "source": [
    "print(\"loaded data set from mnist_1 method\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet_transfer_preparedata(kind='train', no=0): \n",
    "    import skimage.transform\n",
    "\n",
    "    imgs, lbls = [], []\n",
    "\n",
    "    if kind == 'train': \n",
    "        imgs, lbls = load_images_train_32_32_rgb()\n",
    "    elif kind == \"test\": \n",
    "        imgs, lbls = load_images_test_32_32_rgb()\n",
    "\n",
    "\n",
    "    if no != 0: \n",
    "        imgs = imgs[:no]\n",
    "        lbls = lbls[:no]\n",
    "\n",
    "    imgs_resize = []\n",
    "    no_images = len(imgs)\n",
    "    status_print = \"resizing {} / \" +  str(no_images)\n",
    "    print(status_print.format(0), end=\"\\r\")\n",
    "\n",
    "    for i in range(len(imgs)): \n",
    "        img = skimage.transform.resize(\n",
    "            imgs[i], \n",
    "            (38,38),\n",
    "            mode ='constant')\n",
    "        imgs_resize.append(img)\n",
    "        if i % 500 == 0: \n",
    "            print(status_print.format(i), end=\"\\r\")\n",
    "\n",
    "    imgs_resize = np.array(imgs_resize)\n",
    "    print(\"resizing complete: \" + str(imgs_resize.shape))\n",
    "\n",
    "    lbls_str = image_class_to_str(lbls)\n",
    "    return imgs_resize, lbls, lbls_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "resizing 0 / 1000\r",
      "resizing 0 / 1000\r",
      "resizing 500 / 1000\r",
      "resizing complete: (1000, 38, 38, 3)\n",
      "resizing 0 / 250\r",
      "resizing 0 / 250\r",
      "resizing complete: (250, 38, 38, 3)\n"
     ]
    }
   ],
   "source": [
    "train_images, train_labels, train_labels_str = resnet_transfer_preparedata(no=1000)\n",
    "test_images, test_labels, test_labels_str = resnet_transfer_preparedata('test', no=250)\n",
    "\n",
    "train_labels_cat = to_categorical(train_labels, num_classes=10)\n",
    "test_labels_cat = to_categorical(test_labels, num_classes=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "base_model = ResNet50(\n",
    "    include_top = False, \n",
    "    weights = 'imagenet', \n",
    "    input_shape = [38,38,3]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in base_model.layers[:]: \n",
    "    l.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 38, 38, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 44, 44, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 19, 19, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 19, 19, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 19, 19, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 21, 21, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 10, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 10, 10, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 10, 10, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 10, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 10, 10, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 10, 10, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 10, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 10, 10, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 10, 10, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 10, 10, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 10, 10, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 10, 10, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 10, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 10, 10, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 10, 10, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 10, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 10, 10, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 10, 10, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 10, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 10, 10, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 10, 10, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 10, 10, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 10, 10, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 10, 10, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 10, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 10, 10, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 10, 10, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 10, 10, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 10, 10, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 10, 10, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 10, 10, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 10, 10, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 5, 5, 128)    32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 5, 5, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 5, 5, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 5, 5, 128)    147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 5, 5, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 5, 5, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 5, 5, 512)    66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 5, 5, 512)    131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 5, 5, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 5, 5, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 5, 5, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5, 5, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 5, 5, 128)    65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 5, 5, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 5, 5, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 5, 5, 128)    147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 5, 5, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 5, 5, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 5, 5, 512)    66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 5, 5, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 5, 5, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 5, 5, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 5, 5, 128)    65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 5, 5, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 5, 5, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 5, 5, 128)    147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 5, 5, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 5, 5, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 5, 5, 512)    66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 5, 5, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 5, 5, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 5, 5, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 5, 5, 128)    65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 5, 5, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 5, 5, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 5, 5, 128)    147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 5, 5, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 5, 5, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 5, 5, 512)    66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 5, 5, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 5, 5, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 5, 5, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 3, 3, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 3, 3, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 3, 3, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 3, 3, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 3, 3, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 3, 3, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 3, 3, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 3, 3, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 3, 3, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 3, 3, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 3, 3, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 3, 3, 1024)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 2, 2, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 2, 2, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 2, 2, 2048)   0           add_16[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 23,587,712\n",
      "Trainable params: 0\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/anaconda/envs/py35/lib/python3.5/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 38, 38, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 44, 44, 3)    0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 19, 19, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "bn_conv1 (BatchNormalization)   (None, 19, 19, 64)   256         conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 19, 19, 64)   0           bn_conv1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 21, 21, 64)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 10, 10, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2a (Conv2D)         (None, 10, 10, 64)   4160        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2a (BatchNormalizati (None, 10, 10, 64)   256         res2a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 10, 10, 64)   0           bn2a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2b (Conv2D)         (None, 10, 10, 64)   36928       activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2b (BatchNormalizati (None, 10, 10, 64)   256         res2a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 10, 10, 64)   0           bn2a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch2c (Conv2D)         (None, 10, 10, 256)  16640       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "res2a_branch1 (Conv2D)          (None, 10, 10, 256)  16640       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch2c (BatchNormalizati (None, 10, 10, 256)  1024        res2a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn2a_branch1 (BatchNormalizatio (None, 10, 10, 256)  1024        res2a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 10, 10, 256)  0           bn2a_branch2c[0][0]              \n",
      "                                                                 bn2a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 10, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2a (Conv2D)         (None, 10, 10, 64)   16448       activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2a (BatchNormalizati (None, 10, 10, 64)   256         res2b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 10, 10, 64)   0           bn2b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2b (Conv2D)         (None, 10, 10, 64)   36928       activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2b (BatchNormalizati (None, 10, 10, 64)   256         res2b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 10, 10, 64)   0           bn2b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2b_branch2c (Conv2D)         (None, 10, 10, 256)  16640       activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2b_branch2c (BatchNormalizati (None, 10, 10, 256)  1024        res2b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 10, 10, 256)  0           bn2b_branch2c[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 10, 10, 256)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2a (Conv2D)         (None, 10, 10, 64)   16448       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2a (BatchNormalizati (None, 10, 10, 64)   256         res2c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 10, 10, 64)   0           bn2c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2b (Conv2D)         (None, 10, 10, 64)   36928       activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2b (BatchNormalizati (None, 10, 10, 64)   256         res2c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 10, 10, 64)   0           bn2c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res2c_branch2c (Conv2D)         (None, 10, 10, 256)  16640       activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "bn2c_branch2c (BatchNormalizati (None, 10, 10, 256)  1024        res2c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 10, 10, 256)  0           bn2c_branch2c[0][0]              \n",
      "                                                                 activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 10, 10, 256)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2a (Conv2D)         (None, 5, 5, 128)    32896       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2a (BatchNormalizati (None, 5, 5, 128)    512         res3a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 5, 5, 128)    0           bn3a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2b (Conv2D)         (None, 5, 5, 128)    147584      activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2b (BatchNormalizati (None, 5, 5, 128)    512         res3a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 5, 5, 128)    0           bn3a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch2c (Conv2D)         (None, 5, 5, 512)    66048       activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3a_branch1 (Conv2D)          (None, 5, 5, 512)    131584      activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch2c (BatchNormalizati (None, 5, 5, 512)    2048        res3a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn3a_branch1 (BatchNormalizatio (None, 5, 5, 512)    2048        res3a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 5, 5, 512)    0           bn3a_branch2c[0][0]              \n",
      "                                                                 bn3a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 5, 5, 512)    0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2a (Conv2D)         (None, 5, 5, 128)    65664       activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2a (BatchNormalizati (None, 5, 5, 128)    512         res3b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 5, 5, 128)    0           bn3b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2b (Conv2D)         (None, 5, 5, 128)    147584      activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2b (BatchNormalizati (None, 5, 5, 128)    512         res3b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 5, 5, 128)    0           bn3b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3b_branch2c (Conv2D)         (None, 5, 5, 512)    66048       activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3b_branch2c (BatchNormalizati (None, 5, 5, 512)    2048        res3b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 5, 5, 512)    0           bn3b_branch2c[0][0]              \n",
      "                                                                 activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 5, 5, 512)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2a (Conv2D)         (None, 5, 5, 128)    65664       activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2a (BatchNormalizati (None, 5, 5, 128)    512         res3c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 5, 5, 128)    0           bn3c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2b (Conv2D)         (None, 5, 5, 128)    147584      activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2b (BatchNormalizati (None, 5, 5, 128)    512         res3c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 5, 5, 128)    0           bn3c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3c_branch2c (Conv2D)         (None, 5, 5, 512)    66048       activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3c_branch2c (BatchNormalizati (None, 5, 5, 512)    2048        res3c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 5, 5, 512)    0           bn3c_branch2c[0][0]              \n",
      "                                                                 activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 5, 5, 512)    0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2a (Conv2D)         (None, 5, 5, 128)    65664       activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2a (BatchNormalizati (None, 5, 5, 128)    512         res3d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 5, 5, 128)    0           bn3d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2b (Conv2D)         (None, 5, 5, 128)    147584      activation_20[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2b (BatchNormalizati (None, 5, 5, 128)    512         res3d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 5, 5, 128)    0           bn3d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res3d_branch2c (Conv2D)         (None, 5, 5, 512)    66048       activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn3d_branch2c (BatchNormalizati (None, 5, 5, 512)    2048        res3d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 5, 5, 512)    0           bn3d_branch2c[0][0]              \n",
      "                                                                 activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 5, 5, 512)    0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2a (Conv2D)         (None, 3, 3, 256)    131328      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_23[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_24 (Activation)      (None, 3, 3, 256)    0           bn4a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_24[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4a_branch1 (Conv2D)          (None, 3, 3, 1024)   525312      activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn4a_branch1 (BatchNormalizatio (None, 3, 3, 1024)   4096        res4a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 3, 3, 1024)   0           bn4a_branch2c[0][0]              \n",
      "                                                                 bn4a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_25 (Activation)      (None, 3, 3, 1024)   0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_26 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_26[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_27 (Activation)      (None, 3, 3, 256)    0           bn4b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4b_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_27[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4b_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 3, 3, 1024)   0           bn4b_branch2c[0][0]              \n",
      "                                                                 activation_25[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_28 (Activation)      (None, 3, 3, 1024)   0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_29 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_29[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_30 (Activation)      (None, 3, 3, 256)    0           bn4c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4c_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_30[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4c_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 3, 3, 1024)   0           bn4c_branch2c[0][0]              \n",
      "                                                                 activation_28[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_31 (Activation)      (None, 3, 3, 1024)   0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_32 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_32[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4d_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_33 (Activation)      (None, 3, 3, 256)    0           bn4d_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4d_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_33[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4d_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4d_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 3, 3, 1024)   0           bn4d_branch2c[0][0]              \n",
      "                                                                 activation_31[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_34 (Activation)      (None, 3, 3, 1024)   0           add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_35 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_35[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4e_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_36 (Activation)      (None, 3, 3, 256)    0           bn4e_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4e_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_36[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4e_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4e_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 3, 3, 1024)   0           bn4e_branch2c[0][0]              \n",
      "                                                                 activation_34[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 3, 3, 1024)   0           add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2a (Conv2D)         (None, 3, 3, 256)    262400      activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2a (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2b (Conv2D)         (None, 3, 3, 256)    590080      activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2b (BatchNormalizati (None, 3, 3, 256)    1024        res4f_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 3, 3, 256)    0           bn4f_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res4f_branch2c (Conv2D)         (None, 3, 3, 1024)   263168      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn4f_branch2c (BatchNormalizati (None, 3, 3, 1024)   4096        res4f_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 3, 3, 1024)   0           bn4f_branch2c[0][0]              \n",
      "                                                                 activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 3, 3, 1024)   0           add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2a (Conv2D)         (None, 2, 2, 512)    524800      activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5a_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 2, 2, 512)    0           bn5a_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5a_branch1 (Conv2D)          (None, 2, 2, 2048)   2099200     activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5a_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "bn5a_branch1 (BatchNormalizatio (None, 2, 2, 2048)   8192        res5a_branch1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 2, 2, 2048)   0           bn5a_branch2c[0][0]              \n",
      "                                                                 bn5a_branch1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 2, 2, 2048)   0           add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5b_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 2, 2, 512)    0           bn5b_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5b_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5b_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5b_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 2, 2, 2048)   0           bn5b_branch2c[0][0]              \n",
      "                                                                 activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 2, 2, 2048)   0           add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2a (Conv2D)         (None, 2, 2, 512)    1049088     activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2a (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2a[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2a[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2b (Conv2D)         (None, 2, 2, 512)    2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2b (BatchNormalizati (None, 2, 2, 512)    2048        res5c_branch2b[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 2, 2, 512)    0           bn5c_branch2b[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "res5c_branch2c (Conv2D)         (None, 2, 2, 2048)   1050624     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bn5c_branch2c (BatchNormalizati (None, 2, 2, 2048)   8192        res5c_branch2c[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 2, 2, 2048)   0           bn5c_branch2c[0][0]              \n",
      "                                                                 activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 2, 2, 2048)   0           add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_1 (Glo (None, 2048)         0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 2048)         0           global_average_pooling2d_1[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          262272      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           1290        activation_50[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 23,851,274\n",
      "Trainable params: 263,562\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/anaconda/envs/py35/lib/python3.5/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"de...)`\n"
     ]
    }
   ],
   "source": [
    "\n",
    "added_layers = base_model.output \n",
    "\n",
    "# Prior to GAP, one would flatten your tensor and then add a few fully connected layers in your model. \n",
    "# The problem is that a bunch of parameters in your model end up being attributed to the dense layers and \n",
    "# could potentially lead to overfitting. A natural solution was to add dropout to help regulate that.\n",
    "\n",
    "# However a few years ago, the idea of having a Global Average Pooling came into play. \n",
    "# GAP can be viewed as alternative to the whole flatten FC Dropout paradigm. GAP helps prevent overfitting \n",
    "# by doing an extreme form of reduction. Given a H X W X D tensor, GAP will average the H X W features \n",
    "# into a single number and reduce the tensor into a 1 X 1 X D tensor.\n",
    "\n",
    "# The original paper simply applied GAP and then a softmax. However, it's now common to have GAP followed by a FC layer.\n",
    "\n",
    "\n",
    "added_layers = GlobalAveragePooling2D()(added_layers)#  Flatten()(added_layers)\n",
    "added_layers = Dropout(0.7)(added_layers)\n",
    "\n",
    "# initial run was showing very high variance (acc on trainng is good, but acc on val is very poor)\n",
    "# so i added regulisation \n",
    "added_layers = Dense(128, kernel_regularizer=l2(0.01), bias_regularizer=l2(0.01))(added_layers)\n",
    "added_layers = Activation('relu')(added_layers)\n",
    "# added_layers = BatchNormalization()(added_layers)\n",
    "\n",
    "preds = Dense(10, activation ='softmax')(added_layers)\n",
    "\n",
    "final_model = Model(input = base_model.input, outputs=preds)\n",
    "\n",
    "final_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "adam = Adam(lr=0.0001)\n",
    "final_model.compile(optimizer= Adadelta(), loss='categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 38, 38, 3)\n",
      "(250, 38, 38, 3)\n",
      "(1000, 10)\n",
      "(250, 10)\n",
      "1.0 0.0\n",
      "0.9998424854706426 0.0\n"
     ]
    }
   ],
   "source": [
    "train_images = train_images[:1000]\n",
    "train_labels_cat = train_labels_cat[:1000]\n",
    "\n",
    "test_images = test_images[:250]\n",
    "test_labels_cat = test_labels_cat[:250]\n",
    "\n",
    "print(train_images.shape)\n",
    "print(test_images.shape)\n",
    "print(train_labels_cat.shape)\n",
    "print(test_labels_cat.shape)\n",
    "\n",
    "print(np.max(train_images), np.min(train_images))\n",
    "print(np.max(test_images), np.min(test_images))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /data/anaconda/envs/py35/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 1:39 - loss: 6.4818 - acc: 0.0900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 44s - loss: 6.2374 - acc: 0.1000 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 26s - loss: 6.1498 - acc: 0.1100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 16s - loss: 5.9976 - acc: 0.1250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 11s - loss: 5.9532 - acc: 0.1340\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 7s - loss: 5.7700 - acc: 0.1600 \b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 4s - loss: 5.6451 - acc: 0.1829\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 2s - loss: 5.5628 - acc: 0.1950\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 1s - loss: 5.4556 - acc: 0.2111\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 13s 13ms/step - loss: 5.3460 - acc: 0.2290 - val_loss: 4.7391 - val_acc: 0.0840\n",
      "Epoch 2/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 4.3182 - acc: 0.4300\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 4.3209 - acc: 0.4200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 4.3068 - acc: 0.4000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 4.2660 - acc: 0.4025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 4.2191 - acc: 0.4160\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 4.1898 - acc: 0.4350\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 4.1696 - acc: 0.4286\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 4.1331 - acc: 0.4375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 4.0922 - acc: 0.4478\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 740us/step - loss: 4.0575 - acc: 0.4600 - val_loss: 4.6823 - val_acc: 0.0800\n",
      "Epoch 3/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 3.7353 - acc: 0.5500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 3.7629 - acc: 0.5350\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 3.6654 - acc: 0.5600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 3.5933 - acc: 0.5650\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 3.5293 - acc: 0.5900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 3.5668 - acc: 0.5883\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 3.5888 - acc: 0.5829\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 3.5821 - acc: 0.5800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 3.5776 - acc: 0.5800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 713us/step - loss: 3.6061 - acc: 0.5800 - val_loss: 4.6532 - val_acc: 0.0840\n",
      "Epoch 4/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 3.5119 - acc: 0.5600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 3.5654 - acc: 0.5750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 3.4847 - acc: 0.5933\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 3.4724 - acc: 0.5975\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 3.4508 - acc: 0.6100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 3.4369 - acc: 0.6200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 3.3945 - acc: 0.6214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 3.3863 - acc: 0.6288\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 3.3786 - acc: 0.6322\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 733us/step - loss: 3.3550 - acc: 0.6410 - val_loss: 4.5992 - val_acc: 0.0920\n",
      "Epoch 5/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 3.1005 - acc: 0.6200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 3.0353 - acc: 0.6600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 3.0215 - acc: 0.6767\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 3.1328 - acc: 0.6600\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 3.1695 - acc: 0.6540\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 3.1666 - acc: 0.6550\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 3.1869 - acc: 0.6486\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 3.1913 - acc: 0.6425\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 3.2029 - acc: 0.6433\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 733us/step - loss: 3.1832 - acc: 0.6510 - val_loss: 4.5303 - val_acc: 0.1000\n",
      "Epoch 6/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 3.0615 - acc: 0.6900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 2.9655 - acc: 0.7050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 2.9879 - acc: 0.6900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 2.9863 - acc: 0.7025\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 2.9976 - acc: 0.7020\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 2.9680 - acc: 0.7067\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 2.9975 - acc: 0.6886\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 3.0071 - acc: 0.6863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 3.0005 - acc: 0.6844\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 714us/step - loss: 2.9838 - acc: 0.6880 - val_loss: 4.4905 - val_acc: 0.1000\n",
      "Epoch 7/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 2.8114 - acc: 0.7400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 2.7759 - acc: 0.7250\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 2.7798 - acc: 0.7333\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 2.7729 - acc: 0.7375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 2.7509 - acc: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 2.7768 - acc: 0.7300\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 2.7864 - acc: 0.7357\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 2.7831 - acc: 0.7375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 2.7742 - acc: 0.7422\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 716us/step - loss: 2.7835 - acc: 0.7390 - val_loss: 4.4439 - val_acc: 0.1000\n",
      "Epoch 8/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 2.6772 - acc: 0.7700\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 2.7776 - acc: 0.7400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 2.8268 - acc: 0.7167\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 2.8237 - acc: 0.7125\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 2.8250 - acc: 0.7060\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 2.7949 - acc: 0.7217\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 2.7690 - acc: 0.7371\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 2.7656 - acc: 0.7375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 2.7429 - acc: 0.7411\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 722us/step - loss: 2.7220 - acc: 0.7480 - val_loss: 4.3900 - val_acc: 0.1000\n",
      "Epoch 9/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 2.5698 - acc: 0.7500\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 2.5117 - acc: 0.7950\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 2.5657 - acc: 0.7700\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 2.5690 - acc: 0.7725\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 2.5315 - acc: 0.7840\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 2.5313 - acc: 0.7867\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 2.5363 - acc: 0.7843\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 2.5611 - acc: 0.7762\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 2.5621 - acc: 0.7733\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 720us/step - loss: 2.5556 - acc: 0.7790 - val_loss: 4.3445 - val_acc: 0.1000\n",
      "Epoch 10/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 2.4859 - acc: 0.7800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 2.4705 - acc: 0.7850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 2.4873 - acc: 0.7800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 2.5177 - acc: 0.7825\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 2.5325 - acc: 0.7760\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 2.5187 - acc: 0.7800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 2.4884 - acc: 0.7871\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 2.5022 - acc: 0.7850\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 2.5066 - acc: 0.7800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 719us/step - loss: 2.5132 - acc: 0.7800 - val_loss: 4.2814 - val_acc: 0.1000\n",
      "Epoch 11/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 2.2607 - acc: 0.8200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 2.3479 - acc: 0.8100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 2.3738 - acc: 0.8100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 2.4304 - acc: 0.7800\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 2.4267 - acc: 0.7860\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 2.3992 - acc: 0.7983\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 2.4132 - acc: 0.7929\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 2.4397 - acc: 0.7863\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 2.4343 - acc: 0.7833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 716us/step - loss: 2.4226 - acc: 0.7830 - val_loss: 4.2841 - val_acc: 0.1000\n",
      "Epoch 12/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 2.4715 - acc: 0.8100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 2.3175 - acc: 0.8200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 2.2956 - acc: 0.8333\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 2.2738 - acc: 0.8300\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 2.2799 - acc: 0.8280\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 2.2887 - acc: 0.8183\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 2.2857 - acc: 0.8214\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 2.2773 - acc: 0.8225\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 2.2720 - acc: 0.8211\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 719us/step - loss: 2.2818 - acc: 0.8140 - val_loss: 4.2433 - val_acc: 0.1000\n",
      "Epoch 13/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 2.3004 - acc: 0.7700\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 2.2041 - acc: 0.8200\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 2.1851 - acc: 0.8367\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 2.1919 - acc: 0.8375\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 2.2175 - acc: 0.8240\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 2.2281 - acc: 0.8167\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 2.2230 - acc: 0.8157\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 2.2361 - acc: 0.8112\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 2.2392 - acc: 0.8133\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 723us/step - loss: 2.2298 - acc: 0.8120 - val_loss: 4.2065 - val_acc: 0.1000\n",
      "Epoch 14/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 2.1678 - acc: 0.8100\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 2.2629 - acc: 0.7900\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 2.2338 - acc: 0.7833\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 2.1802 - acc: 0.7950\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 2.1582 - acc: 0.8000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 2.1654 - acc: 0.8033\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 2.1596 - acc: 0.8043\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 2.1642 - acc: 0.8050\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 2.1570 - acc: 0.8067\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 711us/step - loss: 2.1450 - acc: 0.8110 - val_loss: 4.1425 - val_acc: 0.1000\n",
      "Epoch 15/15\n",
      "\r",
      " 100/1000 [==>...........................] - ETA: 0s - loss: 2.0509 - acc: 0.9000\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 200/1000 [=====>........................] - ETA: 0s - loss: 2.0407 - acc: 0.8750\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 300/1000 [========>.....................] - ETA: 0s - loss: 2.0877 - acc: 0.8533\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 400/1000 [===========>..................] - ETA: 0s - loss: 2.0745 - acc: 0.8525\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 500/1000 [==============>...............] - ETA: 0s - loss: 2.0961 - acc: 0.8460\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 600/1000 [=================>............] - ETA: 0s - loss: 2.0955 - acc: 0.8400\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 700/1000 [====================>.........] - ETA: 0s - loss: 2.0780 - acc: 0.8443\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 800/1000 [=======================>......] - ETA: 0s - loss: 2.0789 - acc: 0.8438\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      " 900/1000 [==========================>...] - ETA: 0s - loss: 2.0840 - acc: 0.8389\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r",
      "1000/1000 [==============================] - 1s 723us/step - loss: 2.0946 - acc: 0.8350 - val_loss: 4.1083 - val_acc: 0.1000\n"
     ]
    }
   ],
   "source": [
    "history = final_model.fit(\n",
    "    train_images, train_labels_cat, \n",
    "    validation_data= (test_images, test_labels_cat ), \n",
    "    epochs = 15, batch_size = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-7014cdc2d041>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#%%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# We can get our score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images_reshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels_cat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# We can get our score\n",
    "score = model.evaluate(test_images_reshape, test_labels_cat, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 4.108330421447754\n",
      "Test accuracy: 0.10000000029802322\n"
     ]
    }
   ],
   "source": [
    "# We can get our score\n",
    "score = final_model.evaluate(test_images, test_labels_cat, verbose=0)\n",
    "\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['loss', 'acc', 'val_loss', 'val_acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# https://stackoverflow.com/questions/41908379/keras-plot-training-validation-and-test-set-accuracy\n",
    "# https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "print(history.history.keys())\n",
    "#  \"Accuracy\"\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n",
    "# \"Loss\"\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'validation'], loc='upper left')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
